{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8EiXHKhdWjjuAVFZ3ymnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17092003vamsi/213ECE3317/blob/main/MDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"import numpy as np\\n\",\n",
        "        \"\\n\",\n",
        "        \"class SimpleMDP:\\n\",\n",
        "        \"    def __init__(self):\\n\",\n",
        "        \"        self.num_states = 3\\n\",\n",
        "        \"        self.num_actions = 2\\n\",\n",
        "        \"        self.transitions = np.zeros((self.num_states, self.num_actions, self.num_states)) # transition probabilities\\n\",\n",
        "        \"        self.rewards = np.zeros((self.num_states, self.num_actions)) # rewards\\n\",\n",
        "        \"\\n\",\n",
        "        \"        # Define transition probabilities and rewards\\n\",\n",
        "        \"        self.transitions[0, 0, :] = [0.7, 0.3, 0.0]\\n\",\n",
        "        \"        self.transitions[0, 1, :] = [0.0, 0.9, 0.1]\\n\",\n",
        "        \"        self.transitions[1, 0, :] = [0.0, 1.0, 0.0]\\n\",\n",
        "        \"        self.transitions[1, 1, :] = [0.8, 0.2, 0.0]\\n\",\n",
        "        \"        self.transitions[2, :, :] = [0.0, 0.0, 1.0]\\n\",\n",
        "        \"        self.rewards[1, 0] = 1.0\\n\",\n",
        "        \"        self.rewards[1, 1] = 1.0\\n\",\n",
        "        \"        self.rewards[2, :] = 10.0\\n\",\n",
        "        \"\\n\",\n",
        "        \"    def step(self, state, action):\\n\",\n",
        "        \"        next_state_probs = self.transitions[state, action, :]\\n\",\n",
        "        \"        next_state = np.random.choice(self.num_states, p=next_state_probs)\\n\",\n",
        "        \"        reward = self.rewards[state, action]\\n\",\n",
        "        \"        return next_state, reward\\n\",\n",
        "        \"\\n\",\n",
        "        \"class QLearningAgent:\\n\",\n",
        "        \"    def __init__(self, num_states, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\\n\",\n",
        "        \"        self.num_states = num_states\\n\",\n",
        "        \"        self.num_actions = num_actions\\n\",\n",
        "        \"        self.learning_rate = learning_rate\\n\",\n",
        "        \"        self.discount_factor = discount_factor\\n\",\n",
        "        \"        self.epsilon = epsilon\\n\",\n",
        "        \"        self.q_table = np.zeros((num_states, num_actions))\\n\",\n",
        "        \"\\n\",\n",
        "        \"    def choose_action(self, state):\\n\",\n",
        "        \"        if np.random.rand() < self.epsilon:\\n\",\n",
        "        \"            return np.random.choice(self.num_actions)\\n\",\n",
        "        \"        else:\\n\",\n",
        "        \"            return np.argmax(self.q_table[state, :])\\n\",\n",
        "        \"\\n\",\n",
        "        \"    def update_q_table(self, state, action, reward, next_state):\\n\",\n",
        "        \"        best_next_action = np.argmax(self.q_table[next_state, :])\\n\",\n",
        "        \"        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]\\n\",\n",
        "        \"        td_error = td_target - self.q_table[state, action]\\n\",\n",
        "        \"        self.q_table[state, action] += self.learning_rate * td_error\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create MDP\\n\",\n",
        "        \"mdp = SimpleMDP()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Create Q-learning agent\\n\",\n",
        "        \"agent = QLearningAgent(num_states=mdp.num_states, num_actions=mdp.num_actions)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Training\\n\",\n",
        "        \"num_episodes = 1000\\n\",\n",
        "        \"for episode in range(num_episodes):\\n\",\n",
        "        \"    state = np.random.randint(mdp.num_states) # Start from a random state\\n\",\n",
        "        \"    while state != 2: # Continue until reaching the terminal state\\n\",\n",
        "        \"        action = agent.choose_action(state)\\n\",\n",
        "        \"        next_state, reward = mdp.step(state, action)\\n\",\n",
        "        \"        agent.update_q_table(state, action, reward, next_state)\\n\",\n",
        "        \"        state = next_state\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Evaluate\\n\",\n",
        "        \"total_rewards = 0\\n\",\n",
        "        \"num_eval_episodes = 100\\n\",\n",
        "        \"for episode in range(num_eval_episodes):\\n\",\n",
        "        \"    state = 0\\n\",\n",
        "        \"    while state != 2:\\n\",\n",
        "        \"        action = agent.choose_action(state)\\n\",\n",
        "        \"        next_state, reward = mdp.step(state, action)\\n\",\n",
        "        \"        total_rewards += reward\\n\",\n",
        "        \"        state = next_state\\n\",\n",
        "        \"\\n\",\n",
        "        \"average_reward = total_rewards / num_eval_episodes\\n\",\n",
        "        \"print(\\\"Average reward over\\\", num_eval_episodes, \\\"evaluation episodes:\\\", average_reward)\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"P7BEHAYRbcB5\",\n",
        "        \"outputId\": \"636dfebe-38af-4f42-98bc-b01ed7f7d2b0\"\n",
        "      },\n",
        "      \"execution_count\": 14,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Average reward over 100 evaluation episodes: 1618.62\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eowaYUcbCMrj",
        "outputId": "fe98327a-a799-4106-aae9-5990409205bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'nbformat': 4,\n",
              " 'nbformat_minor': 0,\n",
              " 'metadata': {'colab': {'provenance': []},\n",
              "  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n",
              "  'language_info': {'name': 'python'}},\n",
              " 'cells': [{'cell_type': 'code',\n",
              "   'source': ['import numpy as np\\n',\n",
              "    '\\n',\n",
              "    'class SimpleMDP:\\n',\n",
              "    '    def __init__(self):\\n',\n",
              "    '        self.num_states = 3\\n',\n",
              "    '        self.num_actions = 2\\n',\n",
              "    '        self.transitions = np.zeros((self.num_states, self.num_actions, self.num_states)) # transition probabilities\\n',\n",
              "    '        self.rewards = np.zeros((self.num_states, self.num_actions)) # rewards\\n',\n",
              "    '\\n',\n",
              "    '        # Define transition probabilities and rewards\\n',\n",
              "    '        self.transitions[0, 0, :] = [0.7, 0.3, 0.0]\\n',\n",
              "    '        self.transitions[0, 1, :] = [0.0, 0.9, 0.1]\\n',\n",
              "    '        self.transitions[1, 0, :] = [0.0, 1.0, 0.0]\\n',\n",
              "    '        self.transitions[1, 1, :] = [0.8, 0.2, 0.0]\\n',\n",
              "    '        self.transitions[2, :, :] = [0.0, 0.0, 1.0]\\n',\n",
              "    '        self.rewards[1, 0] = 1.0\\n',\n",
              "    '        self.rewards[1, 1] = 1.0\\n',\n",
              "    '        self.rewards[2, :] = 10.0\\n',\n",
              "    '\\n',\n",
              "    '    def step(self, state, action):\\n',\n",
              "    '        next_state_probs = self.transitions[state, action, :]\\n',\n",
              "    '        next_state = np.random.choice(self.num_states, p=next_state_probs)\\n',\n",
              "    '        reward = self.rewards[state, action]\\n',\n",
              "    '        return next_state, reward\\n',\n",
              "    '\\n',\n",
              "    'class QLearningAgent:\\n',\n",
              "    '    def __init__(self, num_states, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\\n',\n",
              "    '        self.num_states = num_states\\n',\n",
              "    '        self.num_actions = num_actions\\n',\n",
              "    '        self.learning_rate = learning_rate\\n',\n",
              "    '        self.discount_factor = discount_factor\\n',\n",
              "    '        self.epsilon = epsilon\\n',\n",
              "    '        self.q_table = np.zeros((num_states, num_actions))\\n',\n",
              "    '\\n',\n",
              "    '    def choose_action(self, state):\\n',\n",
              "    '        if np.random.rand() < self.epsilon:\\n',\n",
              "    '            return np.random.choice(self.num_actions)\\n',\n",
              "    '        else:\\n',\n",
              "    '            return np.argmax(self.q_table[state, :])\\n',\n",
              "    '\\n',\n",
              "    '    def update_q_table(self, state, action, reward, next_state):\\n',\n",
              "    '        best_next_action = np.argmax(self.q_table[next_state, :])\\n',\n",
              "    '        td_target = reward + self.discount_factor * self.q_table[next_state, best_next_action]\\n',\n",
              "    '        td_error = td_target - self.q_table[state, action]\\n',\n",
              "    '        self.q_table[state, action] += self.learning_rate * td_error\\n',\n",
              "    '\\n',\n",
              "    '# Create MDP\\n',\n",
              "    'mdp = SimpleMDP()\\n',\n",
              "    '\\n',\n",
              "    '# Create Q-learning agent\\n',\n",
              "    'agent = QLearningAgent(num_states=mdp.num_states, num_actions=mdp.num_actions)\\n',\n",
              "    '\\n',\n",
              "    '# Training\\n',\n",
              "    'num_episodes = 1000\\n',\n",
              "    'for episode in range(num_episodes):\\n',\n",
              "    '    state = np.random.randint(mdp.num_states) # Start from a random state\\n',\n",
              "    '    while state != 2: # Continue until reaching the terminal state\\n',\n",
              "    '        action = agent.choose_action(state)\\n',\n",
              "    '        next_state, reward = mdp.step(state, action)\\n',\n",
              "    '        agent.update_q_table(state, action, reward, next_state)\\n',\n",
              "    '        state = next_state\\n',\n",
              "    '\\n',\n",
              "    '# Evaluate\\n',\n",
              "    'total_rewards = 0\\n',\n",
              "    'num_eval_episodes = 100\\n',\n",
              "    'for episode in range(num_eval_episodes):\\n',\n",
              "    '    state = 0\\n',\n",
              "    '    while state != 2:\\n',\n",
              "    '        action = agent.choose_action(state)\\n',\n",
              "    '        next_state, reward = mdp.step(state, action)\\n',\n",
              "    '        total_rewards += reward\\n',\n",
              "    '        state = next_state\\n',\n",
              "    '\\n',\n",
              "    'average_reward = total_rewards / num_eval_episodes\\n',\n",
              "    'print(\"Average reward over\", num_eval_episodes, \"evaluation episodes:\", average_reward)\\n'],\n",
              "   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n",
              "    'id': 'P7BEHAYRbcB5',\n",
              "    'outputId': '636dfebe-38af-4f42-98bc-b01ed7f7d2b0'},\n",
              "   'execution_count': 14,\n",
              "   'outputs': [{'output_type': 'stream',\n",
              "     'name': 'stdout',\n",
              "     'text': ['Average reward over 100 evaluation episodes: 1618.62\\n']}]}]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}